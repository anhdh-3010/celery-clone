# Celery Clone - Distributed Task Queue

Má»™t implementation Ä‘Æ¡n giáº£n cá»§a Celery task queue sá»­ dá»¥ng Redis lÃ m message broker. Project nÃ y demo cÃ¡c core concepts cá»§a distributed task queue system.

## ğŸ—ï¸ Architecture

```
Producer (producer.py)
    â†“
Celery App (src/app.py)
    â†“
Redis Broker (src/broker/redis.py)
    â†“
Queues:
â”œâ”€â”€ READY (List)         - Tasks sáºµn sÃ ng xá»­ lÃ½
â”œâ”€â”€ PROCESSING (ZSet)    - Tasks Ä‘ang xá»­ lÃ½ (vá»›i timestamp)
â”œâ”€â”€ SCHEDULED (ZSet)     - Tasks Ä‘Æ°á»£c schedule (vá»›i ETA)
â””â”€â”€ DEAD (List)          - Tasks tháº¥t báº¡i
    â†“
Worker (src/worker/worker.py)
â”œâ”€â”€ Main Loop           - Reserve vÃ  execute tasks
â”œâ”€â”€ Heartbeat Loop      - Gá»­i heartbeat
â”œâ”€â”€ Schedule Poll Loop  - Poll scheduled tasks
â””â”€â”€ Reaper Loop         - Recover expired tasks
```

## ğŸ“¦ Components

### BaseBroker (src/broker/base.py)

Abstract base class Ä‘á»‹nh nghÄ©a interface cho message broker vá»›i cÃ¡c methods:

- `send()`, `reserve()`, `ack()`, `dead()`
- `schedule()`, `poll_schedule()`
- `recover_expired()`
- `send_heartbeat()`, `list_alive_workers()`

### RedisBroker (src/broker/redis.py)

Implementation cá»¥ thá»ƒ sá»­ dá»¥ng Redis data structures:

- **List (READY, DEAD)**: FIFO queue cho messages
- **Sorted Set (PROCESSING, SCHEDULED, WORKERS)**: Tracking vá»›i timestamp

### Reaper (src/broker/reaper.py)

Component Ä‘á»ƒ recover tasks bá»‹ expired:

- PhÃ¡t hiá»‡n tasks trong PROCESSING quÃ¡ lÃ¢u (> visibility_timeout)
- Chuyá»ƒn chÃºng vá» READY queue Ä‘á»ƒ retry

### Worker (src/worker/worker.py)

Worker process vá»›i 3 background threads:

- **Main loop**: Reserve vÃ  execute tasks
- **Heartbeat loop**: Gá»­i heartbeat má»—i 5s
- **Schedule poll loop**: Poll scheduled tasks má»—i 1s
- **Reaper loop**: Recover expired tasks má»—i 10s

### Task (src/task.py)

Task decorator vÃ  execution:

- `@app.task` decorator Ä‘á»ƒ register tasks
- `.delay()` vÃ  `.apply_async()` Ä‘á»ƒ enqueue tasks
- Support `countdown` vÃ  `eta` cho scheduling

### Message (src/message.py)

Message format vá»›i UUID7 ID vÃ  JSON serialization

### Delivery (src/delivery.py)

Wrapper cho reserved message vá»›i metadata

## ğŸš€ Usage

### 1. Start Redis

```bash
docker-compose up -d
```

### 2. Define tasks (producer.py)

```python
from src.app import Celery
from src.broker.redis import RedisBroker

broker = RedisBroker()
app = Celery(broker)

@app.task
def add(x, y):
    return x + y

# Enqueue task
result = add.delay(10, 20)

# Schedule task (cháº¡y sau 5 giÃ¢y)
result = add.apply_async(args=(10, 20), countdown=5)
```

### 3. Run worker

```bash
python run_worker.py
```

## ğŸ”§ Configuration

Worker cÃ³ thá»ƒ configure vá»›i cÃ¡c parameters:

```python
worker = Worker(
    name="worker-1",
    app=app,
    prefetch=1,                    # Sá»‘ tasks láº¥y má»—i láº§n
    heartbeat_interval=5,          # Gá»­i heartbeat má»—i 5s
    schedule_poll_interval=1,      # Poll schedule má»—i 1s
    reaper_interval=10,            # Reaper cháº¡y má»—i 10s
    visibility_timeout=30          # Timeout Ä‘á»ƒ recover tasks
)
```

Task cÃ³ thá»ƒ configure:

```python
@app.task(max_retries=5, default_retry_delay=10)
def my_task():
    pass
```

## ğŸ“Š Redis Data Structures

### Lists

- `celery:ready` - Tasks sáºµn sÃ ng xá»­ lÃ½ (FIFO)
- `celery:dead` - Tasks tháº¥t báº¡i sau max retries

### Sorted Sets (vá»›i score lÃ  timestamp)

- `celery:processing` - Tasks Ä‘ang Ä‘Æ°á»£c xá»­ lÃ½
- `celery:scheduled` - Tasks Ä‘Æ°á»£c schedule (score = ETA)
- `celery:workers` - Workers cÃ²n sá»‘ng (score = last heartbeat)

## ğŸ“ Concepts Learned

1. **Message Queue Pattern**: Producer-Consumer vá»›i Redis
2. **Distributed Task Queue**: Async task execution
3. **Fault Tolerance**: Retry, reaper, visibility timeout
4. **Graceful Shutdown**: Signal handling vÃ  resource cleanup
5. **Background Workers**: Multi-threading cho concurrent operations
6. **Task Scheduling**: Delayed execution vá»›i sorted sets
7. **Heartbeat Mechanism**: Worker liveness tracking

## ğŸ“ TODO / Future Enhancements

- [ ] Result backend Ä‘á»ƒ lÆ°u káº¿t quáº£ tasks
- [ ] Priority queues
- [ ] Task routing (nhiá»u queues)
- [ ] Concurrency (multiprocessing/threading)
- [ ] Monitoring dashboard
- [ ] Task chaining vÃ  workflows
- [ ] Rate limiting
- [ ] Exponential backoff cho retries

---
